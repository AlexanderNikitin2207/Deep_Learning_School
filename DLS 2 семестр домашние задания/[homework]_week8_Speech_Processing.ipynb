{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zahzrEdRCaxV"
      },
      "source": [
        "### Spoken Language Processing\n",
        "В этом задании предлагается обучить классификатор класса возраста по голосу (пример с тем, как это можно сделать для пола см. в семинаре)\n",
        "\n",
        "Подумайте, как лучше предсказывать возраст (может быть разбить на группы?) и какой лосс использовать\n",
        "\n",
        "P.S. не забудьте, что если то вы работает в Colab, то вы можете поменять среду выполнения на GPU/TPU!\n",
        "\n",
        "Вопросы по заданию/материалам: @Nestyme"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade librosa\n",
        "\n",
        "exit()"
      ],
      "metadata": {
        "id": "d2VVpAc-hpWb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wSgHrbiEc8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfdd8d0-ccad-4b58-d0ef-13d1805915a5"
      },
      "source": [
        "!pip3 install timit-utils==0.9.0\n",
        "!pip3 install torchaudio\n",
        "! wget https://ndownloader.figshare.com/files/10256148\n",
        "!unzip -q 10256148"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timit-utils==0.9.0\n",
            "  Downloading timit_utils-0.9.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from timit-utils==0.9.0) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from timit-utils==0.9.0) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from timit-utils==0.9.0) (1.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from timit-utils==0.9.0) (3.7.1)\n",
            "Collecting python-speech-features (from timit-utils==0.9.0)\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: SoundFile>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from timit-utils==0.9.0) (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.8.0->timit-utils==0.9.0) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->timit-utils==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->timit-utils==0.9.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->timit-utils==0.9.0) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->timit-utils==0.9.0) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->timit-utils==0.9.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->timit-utils==0.9.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->timit-utils==0.9.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->timit-utils==0.9.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->timit-utils==0.9.0) (2022.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.8.0->timit-utils==0.9.0) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->timit-utils==0.9.0) (1.16.0)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5869 sha256=e6feeb248eac4592936a91afbad71ae70d97673debb1baf9c6539f20d102e579\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features, timit-utils\n",
            "Successfully installed python-speech-features-0.6 timit-utils-0.9.0\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchaudio) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchaudio) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchaudio) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchaudio) (1.3.0)\n",
            "--2023-08-09 05:10:29--  https://ndownloader.figshare.com/files/10256148\n",
            "Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 52.16.102.173, 54.217.124.219, 2a05:d018:1f4:d000:b283:27aa:b939:8ed4, ...\n",
            "Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|52.16.102.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20230809/eu-west-1/s3/aws4_request&X-Amz-Date=20230809T051029Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=e4029f49c0dd40e9a3bd344987411c904d0d2fafc039af1112098b9d3b7f63c9 [following]\n",
            "--2023-08-09 05:10:29--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20230809/eu-west-1/s3/aws4_request&X-Amz-Date=20230809T051029Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=e4029f49c0dd40e9a3bd344987411c904d0d2fafc039af1112098b9d3b7f63c9\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.52.100, 52.218.24.155, 52.218.98.67, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.52.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 440207227 (420M) [binary/octet-stream]\n",
            "Saving to: ‘10256148’\n",
            "\n",
            "10256148            100%[===================>] 419.81M  32.8MB/s    in 13s     \n",
            "\n",
            "2023-08-09 05:10:43 (31.7 MB/s) - ‘10256148’ saved [440207227/440207227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0bovLZ0Ew5V"
      },
      "source": [
        "import timit_utils as tu\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import IPython\n",
        "_TIMIT_PATH = 'data/lisa/data/timit/raw/TIMIT'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd-qfC9-DdnJ"
      },
      "source": [
        "## Задание 1\n",
        "Загрузите данные для обучения. Для этого:\n",
        "1. Скачайте датасет TIMIT (см семинар)\n",
        "2. Соберите пары \"голос\"  — \"класс возраста\" также, как на семинаре собирались пары \"голос\"  — \"пол\". Аудиодорожки сконвертируйте в мелспектрограммы при помощи `torchaudio либо` `librosa`\n",
        "\n",
        "P.S. вы можете использовать свою реализацию, а можете предложенную (см следующие ячейки)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhPyP4T5DdAD"
      },
      "source": [
        "import timit_utils as tu\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch as t\n",
        "\n",
        "\n",
        "class timit_dataloader:\n",
        "    def __init__(self, data_path=_TIMIT_PATH, train_mode=True, age_mode=True):\n",
        "        self.doc_file_path = os.path.join(data_path, 'DOC', 'SPKRINFO.TXT')\n",
        "        self.corpus = tu.Corpus(data_path)\n",
        "        with open(self.doc_file_path) as f:\n",
        "            self.id_age_dict = dict(\n",
        "                [(tmp.split(' ')[0], 86 - int(tmp.split('  ')[5].split('/')[-1].replace('??', '50'))) \\\n",
        "                 for tmp in f.readlines()[39:]])\n",
        "        if train_mode:\n",
        "            self.trainset = self.create_dataset('train', age_mode=age_mode)\n",
        "            self.validset = self.create_dataset('valid', age_mode=age_mode)\n",
        "        self.testset = self.create_dataset('test', age_mode=age_mode)\n",
        "       # print('id_age_dict:', self.id_age_dict)\n",
        "\n",
        "    def return_age(self, id):\n",
        "       # print('id_age_dict:', self.id_age_dict)\n",
        "        return self.id_age_dict[id]\n",
        "\n",
        "    def return_data(self):\n",
        "        return self.trainset, self.validset, self.testset\n",
        "\n",
        "    def return_test(self):\n",
        "        return self.testset\n",
        "\n",
        "\n",
        "    def create_dataset(self, mode, age_mode=True):\n",
        "        global people\n",
        "        assert mode in ['train', 'valid', 'test']\n",
        "        if mode == 'train':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350)]\n",
        "        if mode == 'valid':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350, 400)]\n",
        "        if mode == 'test':\n",
        "            people = [self.corpus.test.person_by_index(i) for i in range(150)]\n",
        "        spectrograms_and_targets = []\n",
        "        for person in tqdm(people):\n",
        "        #      try:\n",
        "             #     print('person.name:', person.name)\n",
        "             #     print('person.sentences:', person.sentences)\n",
        "                  target = self.return_age(person.name)\n",
        "             #     print('target:', target)\n",
        "                  for i in range(len(person.sentences)):\n",
        "                      spectrograms_and_targets.append(\n",
        "                          self.preprocess_sample(person.sentence_by_index(i).raw_audio, target, age_mode=True))\n",
        "        #      except:\n",
        "        #          print(person.name, target)\n",
        "\n",
        "        X, y = map(np.stack, zip(*spectrograms_and_targets))\n",
        "        X = X.transpose([0, 2, 1])  # to [batch, time, channels]\n",
        "        return X, y\n",
        "\n",
        "  #  def count_class_weights(self, mode=train):\n",
        "  #      _, y = self.create_dataset(mode)\n",
        "  #      print('y labels:', y)\n",
        "\n",
        "    @staticmethod\n",
        "    def spec_to_image(spec, eps=1e-6):\n",
        "        mean = spec.mean()\n",
        "        std = spec.std()\n",
        "        spec_norm = (spec - mean) / (std + eps)\n",
        "        spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "        #spec_scaled = spec_scaled.astype(np.uint8)\n",
        "        return spec_scaled\n",
        "\n",
        "    @staticmethod\n",
        "    def clasterize_by_age(age):\n",
        "        if age <= 25:\n",
        "            return 0\n",
        "        elif 25 < age < 40:\n",
        "            return 1 #0.5\n",
        "        else: # age >= 40:\n",
        "            return 2 #1\n",
        "\n",
        "    def preprocess_sample(self, amplitudes, target, age_mode=True, sr=16000, max_length=150):\n",
        "        spectrogram = librosa.feature.melspectrogram(y=amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        if age_mode:\n",
        "           target = self.clasterize_by_age(target)\n",
        "        else:\n",
        "           target = 0 if target == 'F' else 1\n",
        "        return self.spec_to_image(np.float32(spectrogram)), target\n",
        "\n",
        "    def preprocess_sample_inference(self, amplitudes, sr=16000, max_length=150, device='cpu'):\n",
        "        spectrogram = librosa.feature.melspectrogram(y=amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        spectrogram = np.array([self.spec_to_image(np.float32(spectrogram))]).transpose([0, 2, 1])\n",
        "\n",
        "        return t.tensor(spectrogram, dtype=t.float).to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class dataloader:\n",
        "    def __init__(self, spectrograms, targets):\n",
        "        self.data = list(zip(spectrograms, targets))\n",
        "\n",
        "    def next_batch(self, batch_size, device):\n",
        "        indices = np.random.randint(len(self.data), size=batch_size)\n",
        "     #   print('indices:', indices)\n",
        "\n",
        "        input = [self.data[i] for i in indices]\n",
        "     #   print('input:', input)\n",
        "\n",
        "        source = [line[0] for line in input]\n",
        "     #   print('source:', source)\n",
        "        target = [line[1] for line in input]\n",
        "     #   print('target:', target)\n",
        "\n",
        "        return self.torch_batch(source, target, device)\n",
        "\n",
        "    @staticmethod\n",
        "    def torch_batch(source, target, device):\n",
        "        return tuple(\n",
        "            [\n",
        "                t.tensor(val, dtype=t.float).to(device, non_blocking=True)\n",
        "                for val in [source, target]\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def padd_sequences(lines, pad_token=0):\n",
        "        lengths = [len(line) for line in lines]\n",
        "        max_length = max(lengths)\n",
        "\n",
        "        return np.array(\n",
        "            [\n",
        "                line + [pad_token] * (max_length - lengths[i])\n",
        "                for i, line in enumerate(lines)\n",
        "            ]\n",
        "        )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpz1Q5VOFxLM"
      },
      "source": [
        "Простая сверточная сеть, ее можно дотюнить или поменять по желанию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF9fIVq7Dbwx"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self,  weights=torch.tensor([1, 1, 1], dtype=torch.float), window_sizes=(3, 4, 5)):\n",
        "        super(Model, self).__init__()\n",
        "        self.class_weights = weights.to(device)\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n",
        "            for window_size in window_sizes\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(128 * len(window_sizes), 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.unsqueeze(x, 1)  # [B, C, T, E] Add a channel dim.\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            x2 = F.relu(conv(x))  # [B, F, T, 1]\n",
        "            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n",
        "            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n",
        "            xs.append(x2)\n",
        "        x = torch.cat(xs, 2)  # [B, F, window]\n",
        "\n",
        "        # FC\n",
        "        x = x.view(x.size(0), -1)  # [B, F * window]\n",
        "        logits = self.fc(x)  # [B, class]\n",
        "        probs = torch.softmax(logits, dim=1) #torch.sigmoid(logits).view(-1)\n",
        "        return probs\n",
        "\n",
        "    def loss(self, probs, targets):\n",
        "       # print('type of targets:', targets.long())\n",
        "       # print('type of probs:', probs)\n",
        "        return nn.CrossEntropyLoss(weight=self.class_weights)(probs.float(), targets.long()) #nn.BCELoss()(probs.float(), targets.float())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLUggB9iF6s_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560a8abd-8b79-4752-af8b-c7716b47ea85"
      },
      "source": [
        "_timit_dataloader = timit_dataloader()\n",
        "train, valid, test = _timit_dataloader.return_data()\n",
        "\n",
        "trainset = dataloader(*train)\n",
        "validset = dataloader(*valid)\n",
        "testset = dataloader(*test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [00:51<00:00,  6.86it/s]\n",
            "100%|██████████| 50/50 [00:04<00:00, 10.32it/s]\n",
            "100%|██████████| 150/150 [00:16<00:00,  9.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train[1]"
      ],
      "metadata": {
        "id": "QrONnHhj1O6S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNpxCKWj1OfI",
        "outputId": "6b719b5f-f6ca-489c-916d-d4ce5fd27920"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = torch.tensor([sum([train_label == y for train_label in train_labels]) / len(train_labels) for y in np.unique(train_labels)], dtype=torch.float)"
      ],
      "metadata": {
        "id": "jR5P0odS1o7D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = 1 - class_weights"
      ],
      "metadata": {
        "id": "E-sg599MNYGw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlOquLNP2oy-",
        "outputId": "1a18abf7-fec4-4a53-b436-d90eceab8740"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7400, 0.3857, 0.8743])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScCZEMvXHkmz"
      },
      "source": [
        "#Задание 2\n",
        "1. Обучите свой классификатор категории возраста\n",
        "2. Попробуйте улучшить результат. Можно попробовать усложнить сетку, подвигать границы категорий, поискать новые данные, что угодно, кроме учиться на тесте :)\n",
        "3. Какой подход оказался самым эффективным? Как думаете, почему?\n",
        "4. Как считаете, где можно было бы применить такой классификатор в качестве вспомогательной задачи?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'using {device} mode')\n",
        "patience = 500\n",
        "best_loss = 1000\n",
        "cnt = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkUgmX1Vmq6w",
        "outputId": "84daf058-7ac3-4434-ffc3-75897b271413"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cpu mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(weights=class_weights).to(device)\n",
        "BATCH_SIZE = 64\n",
        "N_ITER = 1000\n",
        "optimizer = Adam(\n",
        "    [p for p in model.parameters() if p.requires_grad], betas=(0.9, 0.999), eps=1e-5\n",
        ")\n",
        "#model.train()"
      ],
      "metadata": {
        "id": "tx7TZXkpm1mS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3qrnKzXm63U",
        "outputId": "c58be92f-0df3-488f-ba94-ef37ff363650"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 198,147 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as t\n",
        "train_loss = 0\n",
        "for i in tqdm(range(N_ITER)):\n",
        "\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    input, target = trainset.next_batch(BATCH_SIZE, device=device)\n",
        "   # print('input:', input[0][0]) # Инпуты почему-то все нули. Но почему??? Как так???\n",
        "   # print('train target:', target)\n",
        "    out = model(input)\n",
        "    loss = model.loss(out, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print('train_loss:', train_loss / (i + 1))\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input, target = validset.next_batch(BATCH_SIZE, device=device)\n",
        "            out = model(input)\n",
        "            valid_loss = model.loss(out, target)\n",
        "            out, target = out.cpu().detach().numpy(), target.cpu().detach().numpy()\n",
        "        #    print('out:', out)\n",
        "         #   print('target:', target)\n",
        "            pred_classes = np.argmax(out, axis=1)\n",
        "          #  print('pred_classes:', pred_classes)\n",
        "           # out = [1. if tmp > 0.5 else 0 for tmp in out]\n",
        "            target = list(map(int, target))\n",
        "            pred_classes = list(pred_classes)\n",
        "            print()\n",
        "           # print('target:', target)\n",
        "           # print('pred_classes:', pred_classes)\n",
        "            print('train_loss:', train_loss / (i + 1))\n",
        "            print(f'accuracy_score:{accuracy_score(pred_classes, target)}')\n",
        "            print(\"i {}, valid {}\".format(i, valid_loss.item()))\n",
        "            print(\"_________\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    if i % 50 == 0 and best_loss > valid_loss.item():\n",
        "        best_loss = valid_loss.item()\n",
        "        cnt = 0\n",
        "    else:\n",
        "        cnt += 1\n",
        "\n",
        "    if cnt > patience:\n",
        "        break\n",
        "print('training finished')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MRNQXvDnNJ1",
        "outputId": "54624637-1c04-4cd0-e9be-d88a2aba3e59"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]<ipython-input-4-30a57e01f847>:122: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  t.tensor(val, dtype=t.float).to(device, non_blocking=True)\n",
            "  0%|          | 1/1000 [00:00<13:36,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.2934173345565796\n",
            "\n",
            "train_loss: 1.2934173345565796\n",
            "accuracy_score:0.546875\n",
            "i 0, valid 1.1863259077072144\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 50/1000 [00:18<05:27,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.1027441094903385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 51/1000 [00:19<06:38,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_loss: 1.1027441094903385\n",
            "accuracy_score:0.5\n",
            "i 50, valid 1.2187273502349854\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 100/1000 [00:37<05:15,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.106174372800506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 101/1000 [00:37<06:19,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_loss: 1.106174372800506\n",
            "accuracy_score:0.609375\n",
            "i 100, valid 1.1251630783081055\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 150/1000 [00:56<05:06,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.1102727714753309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 151/1000 [00:56<07:32,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_loss: 1.1102727714753309\n",
            "accuracy_score:0.59375\n",
            "i 150, valid 1.1339300870895386\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 200/1000 [01:15<04:37,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.110625160867302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 201/1000 [01:16<05:37,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_loss: 1.110625160867302\n",
            "accuracy_score:0.46875\n",
            "i 200, valid 1.2507094144821167\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 250/1000 [01:34<05:07,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.1122485282886552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 251/1000 [01:35<05:47,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_loss: 1.1122485282886552\n",
            "accuracy_score:0.59375\n",
            "i 250, valid 1.1290831565856934\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 301/1000 [01:53<04:49,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.1108290557053397\n",
            "\n",
            "train_loss: 1.1108290557053397\n",
            "accuracy_score:0.59375\n",
            "i 300, valid 1.1355209350585938\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 350/1000 [02:11<03:57,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.110323937869819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 351/1000 [02:12<04:42,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_loss: 1.110323937869819\n",
            "accuracy_score:0.546875\n",
            "i 350, valid 1.1725654602050781\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 400/1000 [02:30<03:25,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.1107332621726609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 401/1000 [02:31<04:10,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_loss: 1.1107332621726609\n",
            "accuracy_score:0.515625\n",
            "i 400, valid 1.2100127935409546\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 451/1000 [02:49<03:54,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.111647319767269\n",
            "\n",
            "train_loss: 1.111647319767269\n",
            "accuracy_score:0.59375\n",
            "i 450, valid 1.1370997428894043\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 500/1000 [03:07<03:05,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.1113425577710012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 501/1000 [03:08<04:27,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_loss: 1.1113425577710012\n",
            "accuracy_score:0.46875\n",
            "i 500, valid 1.2517553567886353\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 551/1000 [03:27<03:07,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.1117491608522765\n",
            "\n",
            "train_loss: 1.1117491608522765\n",
            "accuracy_score:0.546875\n",
            "i 550, valid 1.175399899482727\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 600/1000 [03:45<03:02,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss: 1.111478147907384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 601/1000 [03:45<03:19,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train_loss: 1.111478147907384\n",
            "accuracy_score:0.484375\n",
            "i 600, valid 1.2344472408294678\n",
            "_________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 601/1000 [03:46<02:30,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQwE48TKn0ND"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}